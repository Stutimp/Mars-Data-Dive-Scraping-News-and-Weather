# Web-Scraping

## Module 11 Challenge
I have divided my assignment into two technical products for this Module challenge. They are as follows:

### Part-1
- In this part of the challenge, I have **scraped titles and text previews from Mars News articles** from this https://static.bc-edx.com/data/web/mars_news/index.html Website. I used automated browsing with Splinter and HTML parsing with Beautiful Soup to extract the data from the above website. 
- I worked on Jupyter Notebook to write and execute my codes.
- I stored all the information with title-and-preview pair in a Python dictionary, finally stored the dictionaries in a Python List, and printed the information accordingly. 

### Part- 2
- In this part of the assignment, I again used automated browsing with Splinter and HTML parsing with Beautiful Soup to visit the website https://static.bc-edx.com/data/web/mars_facts/temperature.html,containing the information on Mars Temperature Data in order to **scrape the data and do some required data analysis and data visualizations**.
- I assembled the scrapped data into a Pandas DataFrame with seven column headings: id, terrestrial_data, sol, ls, month, min_temp, and pressure.
- I checked the data types of each column and converted the columns's datatypes into appropriate data types. 
- After analyzing my dataset using pandas functions, I answered some questions.
- Finally, I plotted the results, created data visualizations, and exported the DataFrame into a CSV File.


Thank you!